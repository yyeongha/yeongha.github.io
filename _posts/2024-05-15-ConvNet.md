---
title: 논문리뷰_A ConvNet for the 2020s
categories: [논문리뷰] 
date: 2024-05-15
last_modified_at: 2024-05-15
---

논문 출처 : [A ConvNet for the 2020s](https://arxiv.org/abs/2201.03545v2)

2020년도에 ViT(Vision Transofrmer)가 발표된 이후 Vision task에서 Transformer에 연구가 집중되고 있지만 CNN에 Transformer 구조 및 최신 기법들을 적용한 ConvNeXt라는 모델을 제안하고 있으며 높은 성능을 통해 CNN이 여전히 강하다는 것을 주장하는 논문이다.


# 1. Introduction
2010년대 컴퓨터 비전 분야는 이미지 인식에 탁월한 ConvNets의 발전으로 급성장했다. 

자연어 처리 분야의 ViT(Vision Transformer)가 컴퓨터 비전에 도입되면서 새로운 변화를 맞이했다. ViT는 이미지 분류에는 뛰어났지만 객체 감지나 이미지 분할과 같은 작업에는 한계를 보였다. 

이후 Swin Transformer와 같은 계층적 트랜스포머 모델이 등장하여 ConvNets의 장점을 일부 차용하며 다양한 컴퓨터 비전 작업에서 좋은 성능을 보였다. 

본 논문에서는 ConvNets를 개선하여 트랜스포머 모델만큼의 성능을 내는 ConvNeXt라는 새로운 모델을 제안한다. ConvNeXt는 다양한 벤치마크에서 Swin Transformer와 비슷하거나 더 나은 성능을 보였고, 기존 ConvNets의 단순함과 효율성도 유지했다. 본 연구는 ConvNets가 여전히 컴퓨터 비전 분야에서 중요한 역할을 할 수 있음을 보여주며, 컴퓨터 비전 모델 설계에 새로운 시각을 제시한다. 

![figure1](https://github.com/yyeongha/yyeongha.github.io/blob/main/assets/img/favicons/2024-05-15-img/figure1.png?raw=true) 

중간 선을 기준으로 ImageNet-1K, ImageNet-22K 데이터를 통해서 학습, 사전학습한 모델의 top1 accuracy이다.

각 버블의 면적은 모델 제품군의 변형 FLOP(연산량)에 비례한다. 


※ ViT (vision transformer)
* ViT에서는 입력이미지를 자연어처리의 token과 같이 patch 단위로 나누어 사용하는 것이 핵심. 밑의 사진에서 보이는 patch가 자연어 처리에서의 token과 같다.
* inductive bias가 없어 classification에서는 대용량 데이터에서 ConvNet보다 유리한 면을 보임
* NLP와 같이 patch 단위(16x16)로 이미지를 쪼개서 사용함

![vit](https://github.com/yyeongha/yyeongha.github.io/blob/main/assets/img/favicons/2024-05-15-img/vit.png?raw=true)
![vit2](https://github.com/yyeongha/yyeongha.github.io/blob/main/assets/img/favicons/2024-05-15-img/vit2.png?raw=true)

※ swin
* ViT가 classificatoin이외에서는 좋은 성과가 없자 이를 개선하고자 계층적 구조를 도입함
* ViT와 마찬가지로 patch(4x4) 단위를 씀
* global attention과 local attention을 모두 도입하여 ViT의 큰 연산량보다 최적화된 연산량을 보임

![swin](https://github.com/yyeongha/yyeongha.github.io/blob/main/assets/img/favicons/2024-05-15-img/swin.png?raw=true)



# 2. Modernizing a ConvNet: a Roadmap
본 논문에서는 ResNet-50/200 모델을 시작으로 단계별로 모델 구조를 변경하며 성능을 개선하는 과정을 거쳐, 최종적으로 ConvNeXt라는 새로운 ConvNet 모델을 제안한다. 각 단계는 다음과 같다.

## 1) ResNet-50/200 
resnet 50/200을 베이스로 잡아 transformer의 학습기법을 도입
* epoch을 90 -> 300으로 증가
* AdamW optimizer 사용
* data augmentation(Mixup, Cutmix, RandAugment, Random Erasing) 추가
* Regularization(Stochastic Depth, Label Smoothing.)
-> accuracy : 76.1% -> 78.8% (+2.7%)

이를 통해 전통적인 ConvNet과 ViT의 성능 차이의 많은 부분이 training technques에서 기인하였음을 알 수 있다. 


## 2) macro design
* Changing stage compute ratio
ResNet-50의 경우 stage 마다 블록의 갯수가 3,4,6,3개 이렇게 들어있는데, swin-T의 경우 1:1:3:1로 들어있다. 그래서 ResNet에도 이 비율을 맞춰 3,3,9,3개로 바꾸었다..  
-> accuracy : 78.8% -> 79.4% (+0.6%)

![macro](https://github.com/yyeongha/yyeongha.github.io/blob/main/assets/img/favicons/2024-05-15-img/macro.png?raw=true)

* Changing stem to “Patchify”
기존 모델들의 stem부분을 보면
  * ResNet : stride2, 7x7 conv layer,max pool을 통해 이미지를 4x4로 downsampling
  * ViT : “Patchify”라는 전략을 이용한다. 이미지를 작은 패치로 나누어 각각을 개별 입력 토큰으로 취급하는데, 이 과정에서는 보통 14x14 또는 16x16 크기의 큰 커널과 비중첩(non-overlapping) 컨볼루션을 사용하여 패치를 생성한다.
    * Swin Transformer : 더 작은 4x4형태의 non-overlapping convolution을 사용하여 패치 생성

논문에서는 ResNet을 베이스로 하여 Swin Transformer 방식을 차용하여 stem cell을 4x4 커널 크기의 non-overlapping convolution 레이어를 사용하는 레이어로 대체했다.

-> accuracy : 79.4% -> 79.5% (+0.1%)

![patchify](https://github.com/yyeongha/yyeongha.github.io/blob/main/assets/img/favicons/2024-05-15-img/patchify.png?raw=true)


## 3) ResNeXt
* group convolution 도입
  * 기본 ResNet 구조에서 3x3 convolution layer를 group convolution으로 대체한다. 이는 각 컨볼루션 필터가 입력 채널을 여러 그룹으로 나누어 병렬로 적용된다.
  * group convolution을 사용함으로써, 필터 수를 증가시키지 않으면서도 모델의 용량을 확장할 수 있다. 

  ![resnext](https://github.com/yyeongha/yyeongha.github.io/blob/main/assets/img/favicons/2024-05-15-img/resnext.png?raw=true)

* depthwise convolution 사용

  ![depth](https://github.com/yyeongha/yyeongha.github.io/blob/main/assets/img/favicons/2024-05-15-img/depth.png?raw=true)

* 네트워크 width 증가
  * depthwise convolution으로 인해 FLOPs이 감소하기 때문에, 이를 보완하기 위해 네트워크의 폭을 증가시킨다. 이는 모델의 용량을 증가시켜 성능을 향상시키는 역할을 한다.
-> accuracy : 79.5% -> 80.5 (+1.0%)

※ depthwise convolution
: group convolution의 특수한 경우로, 각 채널별로 독립적인 convolution을 수행한다. 이는 모바일 네트워크(MobileNet)와 같은 경량화된 네트워크에서도 사용된다.


## 4) Inverted Bottleneck
* 차원확장
  * 확장 비율 : MLP 블록의 숨겨진 차원을 입력 차원의 4배로 확장한다. 
  * FLOPs 감소 : 깊이별 convolution layer의 FLOPs가 증가함에도 불구하고, 다운샘플링 잔여 블록의 1x1 convolution layer에서 FLOPs를 크게 줄일 수 있다.
-> accuracy : 80.5% -> 80.6% (+0.1%)

![figure3](https://github.com/yyeongha/yyeongha.github.io/blob/main/assets/img/favicons/2024-05-15-img/figure3.png?raw=true)

(a) ResNeXt (Bottleneck 구조) : 1x1 conv로 채널을 줄인 후 3x3 conv를 진행하고 다시 1x1으로 채널을 키우는 구조

(b) Inverted Bottleneck 

(c) Spatial Depthwise Conv layer 위치 이동

※ Inverted Bottleneck
: MobileNetV2에서 처음 도입된 개념으로, 전통적인 Bottleneck 구조와 반대로 중간층의 차원을 확장하는 방식을 사용한다. 이를 통해 더 많은 특징을 학습할 수 있으며, 네트워크의 표현력을 향상시키는데 도움을 준다.


## 5) 큰 커널 크기
전통적인 ConvNet에서는 작은커널(예:3x3)을 여러 층에 걸쳐 쌓는 방식이 일반적이었는데, 이는 하드웨어 구현이 효율적이고 계산비용이 낮기 때문이다.

ViT에서는 각 층에서 global receptive field를 갖는 non local self attention를 사용한다. 이로인해 각 층에서 더 넓은 영역의 정보를 처리할 수 있게 된다.

Swin Transformer는 self-attention block을 도입하여 최소 7x7 크기의 윈도우를 사용한다. 이를 통해 각층이 더 큰 receptive field를 갖게 된다.

* 깊이별 convolution layer 위치 이동
  * 큰 커널을 사용하기 위한 전제조건으로, 깊이별 convolution layer의 위치를 상위 레이어로 이동시키는 결정을 했다. 이는 Transformer 설계에서 영감을 받은 것으로 복잡하거나 비효울적인 모듈(MSA, large-kernel conv)은 채널수가 적은 상위레이어에서 처리되도록 한다.
* 큰 커널 크기 적용 실험
  * 논문에서는 다양한 커널크기(3, 5, 7, 9, 11)를 실험하여 ConvNet의 성능에 미치는 영향을 평가했다.
  * 3x3 커널에서는 79.9%의 정확도를 기록한 반면, 7x7 커널에서는 80.6%로 성능이 향상되었다. 이는 네트워크의 FLOPs가 거의 동일하게 유지되었음을 의미한다.
-> accuracy : 76.1% -> 78.8% (+2.7%)


## 6) micro design
* BERT와 GPT-2이후 대부분의 Transformer에서는 ReLU보다 GELU를 채택하기 때문에 convnext 또한 GELU로 변경하였다.

![relugelu](https://github.com/yyeongha/yyeongha.github.io/blob/main/assets/img/favicons/2024-05-15-img/relugelu.png?raw=true) 

* 활성화 함수 개수 줄임
  * Transformer 블록에는 각 층마다 활성화 함수가 적게 사용된다. 하지만 전통적인 ResNet블록에서는 각 convolution layer마다 활성화함수를 사용한다.
  * 활성화 함수를 줄이기 위해 잔여블록의 모든 GELU 레이어를 제거하고, 두 1x1 레이어 사이에만 하나의 GELU를 남겼다.

![feweractivate](https://github.com/yyeongha/yyeongha.github.io/blob/main/assets/img/favicons/2024-05-15-img/feweractivate.png?raw=true)

* 정규화 레이어의 개수를 줄임
  * Transformer 블록에는 정규화 레이어도 적게 사용한다. ResNet 블록에서 두 개의 BatchNorm(BN) 레이어를 제거하고, 1x1 레이어 앞에 하나의 BN 레이어만 남겼다.

* Batch Normalization(BN)을 Layer Normalization(LN)으로 변경
  * Batch Normalization(BN)은 ConvNet에서 일반적으로 사용되는 정규화방법이지만, 여러가지 복잡성을 가지고 있어 성능에 부정적인 영향을 미칠 수 있다.
  * Transformer에서는 Layer Normalization(LN)을 사용하며, 이를 ConvNeXt에 적용하였다.
-> accuracy : 80.6% -> 81.5% (+0.9%)

![bntoln](https://github.com/yyeongha/yyeongha.github.io/blob/main/assets/img/favicons/2024-05-15-img/bntoln.png?raw=true)

* 별도의 다운샘플링 레이어
  * ResNet에서는 각 스테이지의 시작부분에서 3x3 convolution과 stride2를 사용하여 공간적 다운 샘플링을 수행한다.
  * Swin Transformer에서는 2x2 convolution 레이어를 사용하여 공간적 다운 샘플링 레이어를 추가한다.
  * 이를 ConvNeXt에도 적용하여, 2x2 convolution 레이어를 사용하여 공간적 다운샘플링을 수행하였다. 이 과정에서 정규화 레이어를 추가하여 훈련을 안정화시켰다.
-> accuracy : 81.5% -> 82.0% (+0.5%)

이러한 단계를 거쳐 개발된 ConvNeXt 모델은 Swin Transformer와 유사한 FLOPs, 파라미터 수, 처리량, 메모리 사용량을 가지면서도, Swin Transformer에 필요한 특별한 모듈 없이도 뛰어난 성능을 보입니다.

![convnext](https://github.com/yyeongha/yyeongha.github.io/blob/main/assets/img/favicons/2024-05-15-img/convnext.png?raw=true)

※ FLOP(FLoating-point OPerations)
: 컴퓨터가 수행하는 부동 소수점 연산 횟수를 의미합니다. 딥러닝 모델의 복잡도를 나타내는 지표로 널리 사용되며, 모델의 학습 및 추론에 필요한 계산량을 추정하는 데 활용됩니다. FLOP이 높을수록 모델이 더 복잡하고 많은 계산이 필요하다는 것을 의미합니다. \
쉽게 말해, FLOP은 모델이 얼마나 많은 계산을 해야 하는지를 나타내는 숫자라고 생각하면 됩니다. 예를 들어, 덧셈, 뺄셈, 곱셈, 나눗셈과 같은 연산을 몇 번 해야 하는지 세는 것이죠. 딥러닝 모델은 수많은 연산을 수행하므로 FLOP은 모델의 크기나 성능을 비교할 때 중요한 기준이 됩니다. 

![figure2](https://github.com/yyeongha/yyeongha.github.io/blob/main/assets/img/favicons/2024-05-15-img/figure2.png?raw=true)



# experiments
![experiment](https://github.com/yyeongha/yyeongha.github.io/blob/main/assets/img/favicons/2024-05-15-img/experiment.png?raw=true)
* ViT, Swin과 같이 다양한 사이즈의 모델들을 구성했다.
* 가운데는 output의 채널 수, 마지막은 block의 수
블록의 수는 1:1:3:1의 비율을 가지고 있다.


## classification
![classification](https://github.com/yyeongha/yyeongha.github.io/blob/main/assets/img/favicons/2024-05-15-img/classification.png?raw=true)

## object detection, segmentation
![ods](https://github.com/yyeongha/yyeongha.github.io/blob/main/assets/img/favicons/2024-05-15-img/ods.png?raw=true)


# conclusion
* 순수 ConvNet: ConvNeXt는 순수한 ConvNet 구조를 기반으로 하여, 트랜스포머 기반의 특화된 모듈 없이도 높은 성능을 발휘한다.
* 효율성: ConvNeXt는 Swin Transformer와 비교하여 더 낮은 FLOPs를 유지하면서도 경쟁력 있는 성능을 보인다.
* 실용성: 이러한 특성 덕분에 ConvNeXt는 다양한 환경에서 더 효율적이고 실용적으로 사용할 수 있다.


---