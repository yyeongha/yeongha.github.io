---
title: [논문리뷰] AlexNet 
use_math: true
---
논문 출처 : https://papers.nips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html

# 2. The Dataset
ImageNet 데이터셋은 22,000개의 카테고리가 있는 150만개의 고해상도 이미지이다. 2010년부터 ILSVRC 대회에서는 ImageNet의 사진 중에서 약 1000개의 카테고리 별로 1000개의 사진을 골라서 대회에서 사용되고 있다. 전체 사진으로 보았을 때는 약 120만 개의 train dataset과 5만 개의 validation dataset, 15만 개의 test dataset을 제공한다. 제공되는 데이터셋의 사진들은 다양한 크기의 사진들이 존재했는데, AlexNet은 고정된 크기의 사진이 필요함에 따라 다음 과정을 거쳤다. 

* 이미지의 가로 세로중 짧은 쪽의 픽셀 수가 256이 되도록 줄인다.
* 256 x 256 의 정사각형 이미지를 얻기 위해 줄인 사진의 중앙을 crop 하여 얻어낸다.
* 각 픽셀의 RGB값을 전체 이미지의 RGB 평균으로 빼준다. 

# 3. The Architecture
alexnet의 구조를 알고 어떤 기법이 사용되었는지 소개한다. 각 기법들을 소개하는 순서는 중요도에 의해 정렬되었으며, 가장 처음에 나오는 기법이 가장 중요한것이다.

## 3.1. ReLU Nonlinearilty
일반적으로 뉴런의 결과를 낼때 활성함수로 하이퍼볼릭 탄젠트나 시그모이드 함수를 이용한다. 하지만 이런 saturating nonlinearities를 사용하는 것보다 non-saturating nonlinearities인 ReLU를 사용하느 것이 학습속도 측면에서 훨씬 빠르다고 주장한다. 

※ saturating nonlinearity
: 입력 x가 무한대로 갈때 함수의 값이 어떤 범위내에서만 움직이는 것

ex) 하이퍼볼릭 탄젠트, 시그모이드 함수
![hyper](/assets/img/favicons/hyperbolic%20tangent.png)
![sigmoid](/assets/img/favicons/igmoid%20activation%20function.png)

※ non-saturating nonlinearity
: 입력 x가 무한대로 갈때 함수의 값이 무한대로 가는 것

ex) ReLU
![relu](/assets/img/favicons/relu.png)

![satu](/assets/img/favicons/satu.png)

위 사진을 보면 점선(saturating nonlinearity)인 하이퍼볼릭 탄젠트 함수를 사용하는 것보다 실선(non-saturating nonlinearity)인 ReLU를 사용하는 것이 학습에러율 25% 이하로 낮추는데 걸리는 시간이 6배 단축된다고 한다. 또한 ReLU를 사용하지 않았다면 엄청난 크기의 신경망을 학습하지 못했을 것이라고 발표하며 ReLU의 사용을 강조하였다.

물론 non-saturating 활성함수의 사용은 AlesNet이 처음은 아니였다. 이전에 |tanh(x)|와 같은 함수를 사용한 논문이 있었으며 위의 함수를 통해 오버피팅을 방지했다는 발표가 있었다. 하지만, AlexNet이 필요로 한것은 빠른 학습속도이었기에 다른 함수를 필요로 했던 것이다.

## 3.2. Training on Multiple GPUs
저자들이 학습에서 사용한 GPU는 GTX 580 GPU 로 3GB의 메모리를 가지고 있는 장비이다. 학습 데이터셋으로 주어지는 120만장의 이미지는 모델을 학습시키지에 충분한 양이었지만, 그 개수와 크기는 GPU가 감당할 수 없었다. 따라서 저자들은 2개의 GPU를 병렬적으로 사용하여 문제를 해결했다. 

다만, 딥러닝의 특정 레이어에서만 2개의 GPU가 서로 데이터를 교환할 수 있게 만들고 나머지 레이어에서는 같은 GPU로부터 연산을 이어받을 수 있게 만들었다. 각각의 GPU는 커널을 절반으로 나누어서 연산을 처리하게 하여 하나에 가해지는 부담을 줄였다. 이 과정은 아래 AlexNet의 구조를 도식화한 부분에서 묘사되어있다.

## 3.3. Local Response Normalization
현재는 Batch Nomalization의 등장으로 잘 사용하지 않는 nomalization기법이지만, 당시에는 ReLU의 결과값이 너무 커져서 주변 뉴런에 영향을 주는 것을 방지하기 위해 nomalization기법이 필요했다. CNN특성상 현재 픽셀에 대한 결과를 계산하기 위해 아웃한 픽셀도 참고하기 때문에 영향을 주는 것이다.

![equ](/assets/img/favicons/equation.png)

* \[a^i_{x,y}\] : (x,y)에 존재하는 픽셀에 대해 i번째 커널을 적용하여 얻은 결과에 
* \[N\] : 레이어에 존재하는 전체 커널의 수
* \[n\] : 인접하다고 판단할 범위 값(하이퍼 파라미터)

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbPOtZf%2FbtrKHZa3rvr%2FU98ZFnlbUR8hn19OMxHT71%2Fimg.jpg)

수식에서 등장하는 상수 \[k\], \[n\], \alpha, \beta 는 하이퍼파라미터로 논문에서는 각 값을  \[k\]=2, \[n\]=5, \alpha=\[10^-4\], \beta=0.75로 설정하였다. 위의 정규화과정은 모든 레이어에서 사용된것은 아니고 특정 레이어에서만 사용되었으며 ReLU를 거치고난 결괏값에 사용하였다. 이 정규화방법을 통해 Top-1 에러율은 1.4%, Top-5에러율은 1.2% 감소시킬 수 있다고 밝혔다.

※ Top-1 에러율, Top-5 에러율
* Top-1 에러율
: 모델이 예측한 확률이 가장 높은 클래스와 실제 정답 클래스가 일치하지 않는 비율. 즉, 모델이 입력이미지에 대해 가장 높은 확률로 예측한 클래스가 실제 정답과 다르면 오분류로 간주하는 것이다. 
예를들어 모델이 어떤 이미지에 대해 '개'라는 클래스에 가장 높은 확률을 부여했지만, 실제 정답이 '고양이'였다면 이는 Top-1 에러에 해당한다.
따라서 Top-1 에러가 낮을수록 모델의 입력이미지를 정확하게 분류하고 있다는 것을 의미하므로, 연구자들은 이 값을 낮추기 위해 다양한 노력을 기울인다. 하지만 ImageNet과 같이 클래스 수가 많고 서로 유사한 클래스가 존재하는데이터셋에서는 Top-1 에러만으로 모델의 성능을 온전히 평가하기 어렵다. 왜냐하면 모델이 정답은 아니지만 정답과 매우 유사한 클래스를 예측했다고 하더라도 Top-1에러에서는 이를 단순히 오분류로 처리하기 때문이다. 이렇나 문제를 보완하기 위해 도입된 것이 Top-5 에러이다.
![top1](https://modulabs.co.kr/wp-content/uploads/2024/03/Screenshot-from-2024-03-19-16-46-47.png)

* Top-5 에러율 
: 모델이 예측한 상위 5개의 클래스 중에 실제 정답 클래스가 포함되어있지 않은 비율이다. 앞서 언급한 예에서 모델이 개, 늑대, 여우, 고양이, 호랑이 수능로 높은 확률을 부여했다면, 비록 고양이가 가장 높은 확률로 예측되지는 않았지만 상위 5개의 클래스 중에서 포함되어있으므로 Top-5 에러에서는 정분류로 간주된다. 
그렇다고 해서 Top-5 에러가 Top-1에러를 완전히 대체할 수 있는 것은 아니다. Top-5에러는 어디까지나 보조적인 지표로, 모델의 실제 정확도를 직접적으로 나타내지는 않는다. 따라서 대부분의 연구자들은 Top-1 에러와 Top-5에러를 함꼐 제시하여 모델의 성능을 다각도로 분석한다.


## 3.4. Overlapping Pooling
기존에 CNN에서는 Pooling을 진행할때 Pooling unit들이 겹쳐져서 연산되는 것이 아니라 겹치지 않게 연산이 이루어졌다. 하지만 저자들은 겹쳐서 Pooling 연산을 수행하여 Top-1 에러율을 0.4%, Top-5 에러율을 0.3% 감소시켰다. (stride = 2, kernel = 3x3)
![op](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbpAmYH%2FbtrKxP8rk9V%2F1cqLtKh2BnulPBZolgGhd1%2Fimg.png)


※ Pooling
: 데이터의 크기를 줄이는 연산을 의미한다. 즉 데이터의 여러값을 묶어서 하나의 데이터로 줄이는 과정이다. Pooling에는 Max Pooling, Average Pooling, Global Average Pooling 등이 있다.
![max pooling](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fbajc7Z%2FbtqEm2FIN6w%2Fb8Li6JX7HsGi8mlipLe4G0%2Fimg.png)

## 3.5. Overall Architecture
이 부분에서는 저자들이 대회에서 사용한 모델의 구조를 설명한다. 모델의 전체 구조는 총 8개의 레이어로 이루어져 있으며 세부적으로는 
5개의 Convolution Network와 3개의 Fully Connected Network로 구성되어있다. Fully Connected 의 마지막 레이어는 1000개의 클래스로 분류하는 Softmax 연산을 거쳐서 최종적으로 1000개의 객체를 분류할 수 있게 만들었다. 

![overall](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fc4sn5U%2FbtrKGO8XWpw%2FmlCWa58ECIDlJ1Szw58QrK%2Fimg.png)

위의 Convolution layer에서 2,4,5번째 레이어는 바로 이전의 GPU에서 연산된 결과를 그대로 가져와서 사용하는 반면, 3번째 레이어에서는 GPUrksdml communication을 통해 이전 레이어에서 연산된 2개의 GPU 결과를 모두 받아오도록 만든 것을 확인할 수 있다. (3번째 레이어에서 점선이 교차되어서 그려진 것을 볼 수 있음)

Fully connected layer는 이전 레이어의 뉴런을 모두 연결하여 받아왔고, 앞서 설명한 Respnse Normalization은 Convolution layer의 첫번째와 두번째 레이어에서 사용되었다. Overlapping Pooling을 진행하는 Max Pool 과정은 Convolution layer의 첫번째, 두번째, 다섯번째 레이어에서 사용되었다. 활성함수로 사용된 ReLU는 모든 레이어(8개)에서 사용되었다.

아래에서 Convolution 연산의 결과를 계산하기 위해서 계산식을 알고있어야 한다. 식에 들어가는 인자는 입력의 크기, 커널의 크기, 커널의 개수, padding, stride의 크기이다. 이 정보들이 있으면 다음 레이어의 출력 크기를 계산하는 것이 가능하다. 이제 아래에서는 이식을 이용하여 각 레이어의 output크기를 연산한다.

![equ](/assets/img/favicons/equ.png)

### 첫번째 convolution layer
논문에서 첫번째 레이어에서 받는 입력의 크기가 224x224x3 크기의 입력을 받는다고 되어있지만, 이후에 이는 오류라고 발표하며 정정된 내용에서는 227x227x3의 입력 이미지를 96개의 커널(11x11x3) 을 stride(4), padding(0)으로 연산을 진행하게 되면 그 출력은 아래와 같이 연산해 볼 수 있다.
![equ2](/assets/img/favicons/equ2.png)

따라서 가로와 세로의 크기가 55이며 채널의 수는 커널의 개수인 96으로 설정되어 55x55x96 의 결과를 얻어낼 수 있다. 하지만 중요한 것은 총 2개의 GPU를 사용하여 커널을 절반으로 나누어 가져가기 때문에 하나의 GPU는 55x55x48의 결과를 받는다. 다음은 큰 값이 주변에 영향을 주지 못하도록 하는 Response normalization을 진행하고 stride(2), kernel(3x3)의 Max Pooling을 진행한다.
![equ3](/assets/img/favicons/equ3.png)

결과적으로 Max Pooling까지 진행했을때 1개의 GPU는 27x27x48의 연산결과를 얻게 되고 이는 다시 2번째 레이어의 입력이 된다. 다시 첫번째 레이어에서 하는 것을 정리하면 다음과 같다. 

* 입력 : 227x227x3 / 커널 : 11x11x3, 96개, stride(4), padding(0)
↓
* GPU 1개의 convolution 연산결과 55x55x48
↓ 
* ReLU
* Response Normalization 진행
↓
* GPU 1개의 Max (Overlapping) Pooling 결과 : 27x27x48

### 두번째 Convolution layer
* 입력 : 27x27x48 / 커널 : 5x5x48, stride(1), padding(2)
↓
* GPU 1개의 Convolution 연산 결과 : 27x27x128
↓
* ReLU
* Response Normaliztion 진행
↓
* GPU 1개의 Max (Overlapping) Pooling 결과 : 13x13x128

### 세번째 Convolution layer
* 입력 : 13x13x128 / 커널 : 3x3x256, stride(1), padding(1)
↓
* GPU 1개의 Convolution 연산 결과 : 13x13x192 (2개의 CPU communication 연산 포함)
↓
* 입력이 communication으로 인해 2개를 전달받기 때문에 커널의 채널크기가 입력채널 크기의 2배
* ReLU

### 네번째 Convolution layer
* 입력 13x13x192 / 커널 : 3x3x192, stride(1), padding(1)
* GPU 1개의 Convolution 연산 결과 : 13x13x192
* ReLU

### 다섯번째 Convolution layer
* 입력 : 13x13x192 / 커널 : 3x3x192, stride(1), padding(1)
* GPU 1개의 Convolution 연산 결과 : 13x13x128
* ReLU

### 3개의 fully connected layer
3개의 fully connected layer에서는 각각 4096개의 뉴런이 존재하며 최종적으로 softmax 연산을 통해 1000개의 객체에 대한 확률을 모델링하도록 설정하였다. 이렇게 AlexNet의 전체 모델 구조를 살펴보았으며 여기에 사용된 파라미터의 개수는 약 6000만개가 된다고 한다. 파라미터의 수가 클수록 또 레이어가 깊어질수록 오버피팅이 발생하기 쉬운데, AlexNet은 이를 해결한 방법에 대해서 그 다음부터 소개하기 시작한다.

# 4. Reducing Overfitting
## 4.1. Data Augmentation
오버피팅을 방지하기 위한 가장 쉽고 좋은 방법은 데이터의 라벨이 변형되지 않는 선에서 데이터를 임의로 추가하여 크게 하는 것이다. 따라서 저자들은 2개의 데이터 증강 방식을 선택했으며 특히 그 연산량이 적어서 따로 저장공간에 저장할 필요 없이 연산할때마다 바로바로 처리할 수 있다고 한다.

첫번째 변형 방법은 좌우반전이다. 이미지 (256x256)를 좌우반전 시켜도 이미지의 라벨은 변하지 않기 때문에 사용할 수 있으며, 변형된 사진에서 다시 랜덤으로 (224x224) 크기의 패치를 얻어내어 입력으로 사용하였다. 이렇게 되면 32x32x2 = 2048배만큼 데이터를 더 늘릴 수 있게 된다. Test시에는 각 꼭지점 네부분의 224x224 패치와 중앙의 패치, 총 5개의 패치 그리고 좌우반전에서 다시 뽑은 5개의 패치를 사용해 총 10개의 패치를 입력으로 넣었다. 저자들은 10개의 패치에 대해 나온 결과를 평균 내어 최종 output으로 산출하였다.
![catLeft/Right Inversion](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FL4xxX%2FbtrKF1nsnVm%2F9XTn3qiaFhQqUWkurYIUHk%2Fimg.png)

두번째 변형 방법은 RGB 채널의 색상강도를 조정하는 방법이다. 주성분분석(PCA)를 진행하고 평균(0), 표준편차(0.1)을 갖는 가우시안 분포에서 랜덤 변수를 추출한 후, 원래의 픽

