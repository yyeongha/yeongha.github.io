---
title: 논문리뷰_ResNet
categories: [논문리뷰] 
date: 2024-06-03
last_modified_at: 2024-06-05
---

논문출처 : [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385)


# 1. Introduction
본 논문에서는 잔차 학습(residual learning) 프레임워크를 통해 기존 심층 신경망의 성능 저하 문제를 해결하고, 매우 깊은 residual network(ResNet)를 성공적으로 훈련하여 ImageNet 데이터 세트에서 뛰어난 성능을 달성했으며, 이는 잔차 학습 원리가 다양한 문제에 적용 가능함을 시사한다.

심층 신경망 학습에서 기울기 소실/폭발 문제는 네트워크 깊이 증가에 따른 어려움을 야기했지만, 정규화된 초기화 및 중간 정규화 레이어를 통해 해결되어 수렴이 가능해졌습니다.
이를 통해 수십 개의 레이어를 가진 네트워크가 확률적 경사 하강법(SGD)과 역전파를 통해 수렴하기 시작할 수 있게 되었습니다.

심층 신경망의 깊이가 증가함에 따라 정확도가 떨어지는 성능 저하 문제는 과적합이 아니라 훈련 오류 증가로 인해 발생하며, 이는 실험을 통해 검증되었습니다. \
그림 1은 일반적인 예를 보여줍니다.
![figure1]()

더 깊은 모델이 더 얕은 모델보다 훈련 오류가 높은 것은 최적화가 어렵기 때문이며, 현재 솔버는 이를 해결하지 못합니다.

본 논문에서는 심층 잔차 학습 프레임워크를 도입하여 성능 저하 문제를 해결합니다. 몇 개의 쌓인 레이어가 원하는 기본 매핑에 직접적으로 맞춰지기를 기대하는 대신, 이러한 레이어들이 명시적으로 잔차 매핑에 맞춰지도록 합니다. \
공식적으로 원하는 기본 매핑을 H(x)라고 하면, 쌓인 비선형 레이어가 F(x) := H(x) - x라는 다른 매핑에 맞춰지도록 합니다. 따라서 원래 매핑은 F(x) + x로 재구성됩니다. 잔차 매핑을 최적화하는 것이 원래의 참조되지 않은 매핑을 최적화하는 것보다 더 쉽다고 가정합니다. 극단적인 경우, 항등 매핑이 최적이라면 비선형 레이어 스택으로 항등 매핑을 맞추는 것보다 잔차를 0으로 만드는 것이 더 쉬울 것입니다.

F(x) + x 공식은 "shortcut connections"을 사용하는 feedforward neural networks로 구현할 수 있습니다(그림 2). Shortcut connections는 한 개 이상의 레이어를 건너뛰는 연결입니다. 본 논문에서는 shortcut connections가 단순히 항등 매핑을 수행하며, 그 출력값이 쌓인 레이어의 출력값에 더해집니다(그림 2). 항등 shortcut connections는 추가적인 매개변수나 계산 복잡성을 증가시키지 않습니다. 전체 네트워크는 여전히 역전파를 사용하여 SGD(확률적 경사 하강법)로 종단 간 훈련될 수 있으며, 솔버를 수정하지 않고도 일반적인 라이브러리(예: Caffe)를 사용하여 쉽게 구현할 수 있습니다. 
![figure1]()

ImageNet에 대한 종합적인 실험을 통해 성능 저하 문제를 보여주고 본 논문에서 제안하는 방법을 평가합니다. 본 논문의 실험 결과는 다음과 같습니다. 
1) 매우 깊은 residual net은 최적화하기 쉽지만, 단순히 레이어를 쌓는 "일반(plain)" net은 깊이가 증가할 때 더 높은 훈련 오류를 보입니다. 
2) 깊은 residual net은 깊이를 크게 늘려 정확도를 쉽게 높일 수 있으며, 이전 네트워크보다 훨씬 더 나은 결과를 생성합니다. 

CIFAR-10 세트에서도 유사한 현상이 나타나며, 이는 최적화의 어려움과 본 논문에서 제안하는 방법의 효과가 특정 데이터 세트에만 국한되지 않는다는 것을 시사합니다. 본 논문에서는 이 데이터 세트에 대해 100개 이상의 레이어를 가진 모델을 성공적으로 훈련했으며, 1000개 이상의 레이어를 가진 모델도 탐색합니다.

ImageNet 분류 데이터 세트에서 매우 깊은 residual net을 통해 훌륭한 결과를 얻었습니다. 152개 레이어의 residual net은 ImageNet에 대해 제시된 네트워크 중 가장 깊지만 VGG net보다 복잡성은 낮습니다. 앙상블은 ImageNet 테스트 세트에서 3.57%의 top-5 오류를 달성했으며 ILSVRC 2015 분류 대회에서 1위를 차지했습니다. 매우 깊은 표현은 다른 인식 작업에서도 뛰어난 일반화 성능을 보여 ImageNet 감지, ImageNet 지역화, COCO 감지 및 COCO 분할에서 1위를 차지했습니다. 이러한 강력한 증거는 잔차 학습 원리가 일반적이며 다른 비전 및 비전 문제에도 적용할 수 있음을 보여줍니다.

# 2. 



























---