---
title: AI-DX education 3조_알약 프로젝트_2
categories: [Project] 
date: 2024-06-12
last_modified_at: 2024-06-12
---
# 오늘 해야할일
1. yolo 딱 맞게 자른 사진 학습해보기
2. yolo rembg 자르기
3. yolo랑 resnet 합치기
4. test_code2 폴더 3.10으로 변환해서 다시 올리기


# 1. yolo 딱 맞게 자른 사진 학습해보기
## 1) 원천데이터_배경이 있는 데이터로 학습
지금까지 나는 데이터 담당 조원분이 만드신 데이터를 사용하지 않고 내가 직접 roboflow에서 만들어서 사용했었다. 
그 이유는 나는 내가 훈련시킨 모델을 샘플 데이터로 학습시켜서 성능을 먼저 보려고 했기 때문이다. 
데이터 담당 조원분이 만드신 데이터는 최종 모델에 맞게 만들어주신 데이터라 모든 데이터(약 590메가)가 있기 때문에 학습하는데 오래 걸릴 것 같았다.
두번째로 모든 데이터를 조금씩 가져와서 샘플데이터를 만드는 방법이 있는데 왜 그 방법은 안했느냐? 그렇게 만들면 시간이 오래 걸릴 것 같았다. 샘플 폴더에 조금조금씩 train, valid, test를 옮기는데 시간이 너무 오래 걸릴 것 같았고, roboflow에 원천 데이터를 넣으면 자동으로 이미지 라벨링도 해주고 train, valid, test, data.yaml까지 자동으로 만들어주기 때문에 시간을 아끼고자 원천데이터를 활용해서 roboflow로 만든 데이터셋을 사용했었다.

내가 만든 데이터셋으로 yolov8을 테스트한 결과.. 
![noDetect]()
![noDetectPill]()

아무것도 감지하지 못함....

그래서 아무래도 이건 데이터에 문제가 있다고 판단을 했다.
이유1. yolo는 학습 코드를 튜닝해서 사용한것도 아니고 있는 그대로의 yolov8 모델에 epoch 200으로 학습을 시켰는데 안된 것은 데이터밖에 없다. 나는 train, valid, test 합쳐서 총 852개의 데이터로 에폭도 200으로 충분히 학습시켰기 때문에 감지를 못할수가 없다.
이유2. 나의 생각이지만 원천 데이터는 다양한 배경에서 여러개의 알약사진, 단일알약사진 등등 다양한 데이터로 학습시킨게 아니기 때문에 감지를 못했다.


## 2) roboflow_다양한 데이터셋으로 학습
-> 그래서 나는 roboflow에서 다른 사람들이 만든 알약 데이터를 가져와서 학습시키고 테스트 해보기로 했다.
https://universe.roboflow.com/project-qugef/ai-drug-analysis-service

이 데이터셋을 보면 알약 하나만 있는사진, 여러개 있는 사진, 손에 올려놓은 사진 등 다양한 환경에서 찍힌 사진이 많아서 이 데이터셋으로 다시한번 학습시키기로 결정했다.
![roboData]()

똑같은 코드로 데이터만 바꾼채 학습시킨 결과
![pillAllDetect]()

아주아주아주 객체 인식을 잘했다. 감지율도 높고!
이때 내가 결론을 내린 것은 첫번째 시도에서 감지하지 못한 것은 데이터셋이 다양하지 않아서이다 라고 결론을 내렸다.


## 3) 원천데이터_경사가 있는 이미지로 테스트
하지만 강사님께 여쭤보니 아마 첫번째 시도에서 내가 위에서 찍은 알약데이터를 학습시켰기 때문에 경사지게 찍은 알약은 인식을 못한것이다..라고 결론이 나왔다.
그래서 첫번째 코드로 정면으로 찍힌 알약들을 테스트해봤는데
![pillDetect]()
-> 감지를 하긴 한다!


## 4) 최종 결론
사용자에게 알약을 촬영할때 위에서 바르게 찍으라고 메세지를 보내야하기로 결정했다. 왜냐하면 어차피 알약각인 ocr을 할때도 위에서 바르게 찍은 사진이 필요하기 때문이다. 

그리고 나는 내가 roboflow에서 만든 데이터셋으로 테스트를 했었는데, 이 데이터셋은 알약 배경(검정)이 있는 데이터이다. 하지만 조원분이 만드신 데이터는 알약크기에 맞춰서 자르고 라벨도 그에 맞춰서 측정한 데이터이다. 강사님께서는 이론상으로 조원분이 만드신 데이터가 잘 작동할 것이라고 생각하지만, 강사님께서는 그렇게 사용해본적이 없어서 조원분이 만드신 데이터로 학습시켜봐야 정확한 것을 알 수 있다고 하셨다.

* 최최종결론
=> 조원분이 만든 데이터셋으로 yolo를 학습시키고 테스트할때는 여러개의 알약이 있는 위에서 바르게 찍은 이미지로 테스트!


## 5) 조원분데이터로 학습
데이터가 너무 커서 코랩 a100으로 돌렸는데, 런타임이 끊어지고 너무 오래 걸려서 조원분이 샘플데이터를 만들어주신다고 했다. 총 2542개의 이미지이다.
같은 코드를 사용해서 이 데이터로 학습시켰더니 
![pills1]()
![pills5]()
![pills_test]()
어떤거는 전체를 인식하고 어떤거는 하나만 인식하고 어떤거는 모두 다 인식한다.

하지만 성능을 보면
![results]()
![PR_curve]()
![R_curve]()
![map]()
성능이 0.995로 매우 좋음.. 그러나 인식을 못함.....
그래서 강사님께 여쭤봤더니 yaml파일의 클래스를 capsule, tablet..이런 약의 종류로 해서 그럴 수도 있다고 하셨다. 그래서 클래스를 조원분이 약이름으로 바꿔서 주시면 그걸로 다시 yolo를 해보기로 했다.


# 2. rembg
조원분이 만들어주시는 동안 rembg를 해보겠다.
우선 잘나왔던 알약의 바운딩박스 라벨을 추출해서 저장한 뒤 그 라벨을 이용해서 알약들을 자르고 배경을 삭제한 뒤 알약들을 각각 저장한다.
![class_0_3]()
![class_1_2]()
![class_2_4]()
![class_4_1]()

성공!! 

# 3. resnet에 rembg로 자른 이미지를 넘겨줘서 각 알약의 클래스를 예측 

그리고 만약 데이터 정리되시면 전체데이터(590메가)는 강사님 폴더에 넣어주시구 샘플데이터는 



project_
    ├── dataset                  # 데이터셋 폴더
    │   ├── train                # 학습 데이터셋
    │   ├── validation           # 검증 데이터셋
    │   ├── test                 # 테스트 데이터셋
    │   └── data.yaml            # 데이터셋 설정 파일

    ├── results                  # 모델 학습 결과 및 체크포인트
    │   ├── weights
    │   │   ├── best_model.pt    # 최적의 모델 가중치
    │   │   └── last_model.pt    # 마지막 에폭 모델 가중치
    │   ├── logs                 # 학습 로그 파일
    │   └── metrics              # 학습 및 검증 성능 지표

    ├── test_results             # 테스트 결과
    │   ├── detected_images      # 테스트 결과 이미지
    │   └── labels               # 테스트 결과 레이블

    └── rembg_img                # 잘라낸 이미지 저장
        ├── class_1              # 클래스별 잘라낸 이미지
        ├── class_2
        └── class_n





























---