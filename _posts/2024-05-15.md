---
title: [논문리뷰] A ConvNet for the 2020s
---

# 1. Introduction
2010년대는 딥러닝의 엄청난 발전과 그 영향으로 대표되는 시기였습니다. 딥러닝의 발전은 신경망, 특히 이미지 인식에 널리 사용되는 합성곱 신경망(ConvNets) 덕분에 가능했습니다. 2010년대 동안 시각 인식 분야는 이미지의 특징을 사람이 직접 설계하던 방식에서 벗어나, ConvNet 모델의 구조를 설계하는 방식으로 성공적으로 전환했습니다. 역전파(back-propagation) 알고리즘으로 훈련된 ConvNet은 이미 1980년대에 발명되었지만 [42], 이미지 특징 학습에 대한 진정한 잠재력을 보여준 것은 2012년 후반이었습니다. AlexNet [40]의 등장은 이미지 인식 분야의 혁신적인 순간을 가져왔고 [59], 컴퓨터 비전의 새로운 시대를 열었습니다. 그 이후로 컴퓨터 비전 분야는 빠른 속도로 발전했습니다. VGGNet [64], Inceptions [68], ResNe(X)t [28, 87], DenseNet [36], MobileNet [34], EfficientNet [71], RegNet [54]와 같은 대표적인 ConvNet 모델들은 정확도, 효율성, 확장성 등 다양한 측면에서 발전을 이루었고, 많은 유용한 설계 원칙들을 널리 알렸습니다.

컴퓨터 비전 분야에서 ConvNet이 완전히 지배적인 위치를 차지하게 된 것은 우연이 아닙니다. 많은 응용 분야에서, 특히 고해상도 이미지를 다룰 때 "슬라이딩 윈도우" 방식은 시각 처리에 필수적입니다. ConvNet은 다양한 컴퓨터 비전 응용 프로그램에 적합하게 만드는 몇 가지 내장된 편향을 가지고 있습니다. 가장 중요한 것은 translation equivariance(이미지 내 객체의 위치가 변해도 객체를 인식하는 능력)이며, 이는 객체 감지와 같은 작업에 매우 중요한 속성입니다. 또한 ConvNet은 슬라이딩 윈도우 방식으로 사용될 때 계산이 공유되기 때문에 [62] 본질적으로 효율적입니다. 수십 년 동안 이러한 특징은 ConvNet을 사용하는 기본적인 방식이었으며, 일반적으로 숫자 [43], 얼굴 [58, 76], 보행자 [19, 63]와 같은 제한된 종류의 객체에 대해 사용되었습니다. 2010년대에 들어서면서 영역 기반 탐지기 [23, 24, 27, 57]는 ConvNet을 시각 인식 시스템의 핵심 구성 요소로 더욱 발전시켰습니다.

거의 같은 시기에 자연어 처리(NLP)를 위한 신경망 설계는 트랜스포머(Transformer)가 순환 신경망(RNN)을 대체하여 주류가 되면서 매우 다른 길을 걷게 되었습니다. 언어와 시각 영역 간에 관심 있는 작업은 다르지만 놀랍게도 두 흐름은 2020년 Vision Transformers (ViT)의 도입으로 극적으로 수렴하여 네트워크 아키텍처 설계의 지형을 완전히 바꿔놓았습니다. 이미지를 패치 시퀀스로 분할하는 초기 "패치화" 계층을 제외하고 ViT는 이미지 관련 유도 바이어스를 도입하지 않으며 원래 NLP Transformer를 최소한으로 변경합니다. ViT의 주요 초점 중 하나는 확장 동작입니다. 더 큰 모델 및 데이터 세트 크기의 도움으로 Transformer는 표준 ResNet보다 훨씬 더 나은 성능을 발휘할 수 있습니다. 이미지 분류 작업에 대한 이러한 결과는 고무적이지만 컴퓨터 비전은 이미지 분류에만 국한되지 않습니다. 앞서 논의했듯이 지난 10년 동안 수많은 컴퓨터 비전 작업에 대한 해결책은 슬라이딩 윈도우, 완전 컨볼루션 패러다임에 크게 의존했습니다. ConvNet 유도 편향 없이 바닐라 ViT 모델은 일반적인 비전 백본으로 채택되는 데 많은 어려움에 직면합니다. 가장 큰 문제는 입력 크기에 대해 2차 복잡도를 갖는 ViT의 글로벌 어텐션 디자인입니다. ImageNet 분류에는 허용될 수 있지만 더 높은 해상도의 입력으로는 빠르게 다루기 어려워집니다.

계층적 Transformer는 이러한 격차를 해소하기 위해 하이브리드 접근 방식을 사용합니다. 예를 들어 Transformer에 "슬라이딩 윈도우" 전략(예: 로컬 윈도우 내에서 주의)을 다시 도입하여 ConvNet과 더 유사하게 동작하도록 했습니다. Swin Transformer[45]는 Transformer를 일반적인 비전 백본으로 채택하고 이미지 분류를 넘어 다양한 컴퓨터 비전 작업에서 최첨단 성능을 달성할 수 있음을 처음으로 보여주었습니다. Swin Transformer의 성공과 빠른 채택은 또 한 가지 사실을 밝혀냈습니다. 컨볼루션의 본질은 무관해지지 않습니다. 오히려 여전히 많은 것이 요구되며 결코 사라지지 않았습니다.

이러한 관점에서 컴퓨터 비전을 위한 Transformer의 발전은 컨볼루션을 다시 가져오는 것을 목표로 했습니다. 그러나 이러한 시도에는 비용이 따릅니다. 슬라이딩 윈도우 자체 주의를 순진하게 구현하면 비용이 많이 들 수 있습니다[55]. 순환 이동 [45]과 같은 고급 접근 방식을 사용하면 속도를 최적화할 수 있지만 시스템 설계가 더욱 정교해집니다. 반면에 ConvNet이 이미 간단하고 꾸밈없는 방식으로 이러한 많은 바람직한 속성을 충족한다는 것은 거의 아이러니합니다. ConvNet이 힘을 잃는 것처럼 보이는 유일한 이유는 (계층적) Transformer가 많은 비전 작업에서 이를 능가하고 성능 차이는 일반적으로 Transformer의 뛰어난 확장 동작으로 인한 것으로, 다중 헤드 자체 주의가 핵심 구성 요소입니다.

지난 10년 동안 점진적으로 개선된 ConvNet과 달리 Vision Transformers의 채택은 단계적인 변화였습니다. 최근 문헌에서 시스템 수준 비교(예: Swin Transformer 대 ResNet)는 일반적으로 둘을 비교할 때 채택됩니다. ConvNet과 계층적 비전 Transformer는 동시에 서로 다르고 유사해집니다. 둘 다 유사한 유도 편향을 갖추고 있지만 훈련 절차 및 매크로/마이크로 수준 아키텍처 설계가 크게 다릅니다. 이 작업에서는 ConvNet과 Transformer 간의 아키텍처 차이점을 조사하고 네트워크 성능을 비교할 때 혼동되는 변수를 식별하려고 합니다. 본 연구는 ConvNet의 ViT 이전 시대와 ViT 이후 시대 간의 격차를 해소하고 순수 ConvNet이 달성할 수 있는 한계를 테스트하기 위한 것입니다.

이를 위해 개선된 절차로 훈련된 표준 ResNet(예: ResNet50)부터 시작합니다. 계층적 비전 Transformer(예: Swin-T) 구성을 위해 아키텍처를 점진적으로 "현대화"합니다. 본 연구는 Transformer의 설계 결정이 ConvNet의 성능에 어떤 영향을 미치는지라는 주요 질문에 의해 진행됩니다. 그 과정에서 성능 차이에 기여하는 몇 가지 주요 구성 요소를 발견합니다. 결과적으로 ConvNeXt라고 불리는 순수 ConvNet 제품군을 제안합니다. ImageNet 분류 [17], COCO의 객체 감지/분할 [44] 및 ADE20K의 의미 분할과 같은 다양한 비전 작업에서 ConvNeXt를 평가합니다 [92]. 놀랍게도 표준 ConvNet 모듈로 전체 구성된 ConvNeXt는 모든 주요 벤치마크에서 정확도, 확장성 및 견고성 측면에서 Transformer에 필적하는 성능을 보입니다. ConvNeXt는 표준 ConvNet의 효율성을 유지하며 교육 및 테스트 모두에 대한 완전 컨볼루션 특성으로 인해 구현이 매우 간단합니다. 우리는 이러한 새로운 결과와 논의가 몇 가지 일반적인 믿음에 도전하고 컴퓨터 비전에서 컨볼루션의 중요성을 재고하도록 사람들을 격려하기를 바랍니다.

# 2. 





























---