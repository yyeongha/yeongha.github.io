---
title: [논문리뷰] A ConvNet for the 2020s
---

# 1. Introduction
2010년대는 딥러닝의 엄청난 발전과 그 영향으로 대표되는 시기였습니다. 딥러닝의 발전은 신경망, 특히 이미지 인식에 널리 사용되는 합성곱 신경망(ConvNets) 덕분에 가능했습니다. 2010년대 동안 시각 인식 분야는 이미지의 특징을 사람이 직접 설계하던 방식에서 벗어나, ConvNet 모델의 구조를 설계하는 방식으로 성공적으로 전환했습니다. 역전파(back-propagation) 알고리즘으로 훈련된 ConvNet은 이미 1980년대에 발명되었지만, 이미지 특징 학습에 대한 진정한 잠재력을 보여준 것은 2012년 후반이었습니다. AlexNet의 등장은 이미지 인식 분야의 혁신적인 순간을 가져왔고, 컴퓨터 비전의 새로운 시대를 열었습니다. 그 이후로 컴퓨터 비전 분야는 빠른 속도로 발전했습니다. VGGNet, Inceptions, ResNext, DenseNet, MobileNet, EfficientNet, RegNet와 같은 대표적인 ConvNet 모델들은 정확도, 효율성, 확장성 등 다양한 측면에서 발전을 이루었고, 많은 유용한 설계 원칙들을 널리 알렸습니다.

컴퓨터 비전 분야에서 ConvNet이 완전히 지배적인 위치를 차지하게 된 것은 우연이 아닙니다. 많은 응용 분야에서, 특히 고해상도 이미지를 다룰 때 "슬라이딩 윈도우" 방식은 시각 처리에 필수적입니다. ConvNet은 다양한 컴퓨터 비전 응용 프로그램에 적합하게 만드는 몇 가지 내장된 편향을 가지고 있습니다. 가장 중요한 것은 translation equivariance(이미지 내 객체의 위치가 변해도 객체를 인식하는 능력)이며, 이는 객체 감지와 같은 작업에 매우 중요한 속성입니다. 또한 ConvNet은 슬라이딩 윈도우 방식으로 사용될 때 계산이 공유되기 때문에 본질적으로 효율적입니다. 수십 년 동안 이러한 특징은 ConvNet을 사용하는 기본적인 방식이었으며, 일반적으로 숫자, 얼굴, 보행자와 같은 제한된 종류의 객체에 대해 사용되었습니다. 2010년대에 들어서면서 영역 기반 탐지기는 ConvNet을 시각 인식 시스템의 핵심 구성 요소로 더욱 발전시켰습니다.

거의 같은 시기에 자연어 처리(NLP)를 위한 신경망 설계는 트랜스포머(Transformer)가 순환 신경망(RNN)을 대체하여 주류가 되면서 매우 다른 길을 걷게 되었습니다. 언어와 시각 영역 간에 관심 있는 작업은 다르지만 놀랍게도 두 흐름은 2020년 Vision Transformers (ViT)의 도입으로 극적으로 수렴하여 네트워크 아키텍처 설계의 지형을 완전히 바꿔놓았습니다. 이미지를 패치 시퀀스로 분할하는 초기 "패치화" 계층을 제외하고 ViT는 이미지 관련 유도 바이어스를 도입하지 않으며 원래 NLP Transformer를 최소한으로 변경합니다. ViT의 주요 초점 중 하나는 확장 동작입니다. 더 큰 모델 및 데이터 세트 크기의 도움으로 Transformer는 표준 ResNet보다 훨씬 더 나은 성능을 발휘할 수 있습니다. 이미지 분류 작업에 대한 이러한 결과는 고무적이지만 컴퓨터 비전은 이미지 분류에만 국한되지 않습니다. 앞서 논의했듯이 지난 10년 동안 수많은 컴퓨터 비전 작업에 대한 해결책은 슬라이딩 윈도우, 완전 컨볼루션 패러다임에 크게 의존했습니다. ConvNet 유도 편향 없이 바닐라 ViT 모델은 일반적인 비전 백본으로 채택되는 데 많은 어려움에 직면합니다. 가장 큰 문제는 입력 크기에 대해 2차 복잡도를 갖는 ViT의 글로벌 어텐션 디자인입니다. ImageNet 분류에는 허용될 수 있지만 더 높은 해상도의 입력으로는 빠르게 다루기 어려워집니다.

계층적 Transformer는 이러한 격차를 해소하기 위해 하이브리드 접근 방식을 사용합니다. 예를 들어 Transformer에 "슬라이딩 윈도우" 전략(예: 로컬 윈도우 내에서 주의)을 다시 도입하여 ConvNet과 더 유사하게 동작하도록 했습니다. Swin Transformer[45]는 Transformer를 일반적인 비전 백본으로 채택하고 이미지 분류를 넘어 다양한 컴퓨터 비전 작업에서 최첨단 성능을 달성할 수 있음을 처음으로 보여주었습니다. Swin Transformer의 성공과 빠른 채택은 또 한 가지 사실을 밝혀냈습니다. 컨볼루션의 본질은 무관해지지 않습니다. 오히려 여전히 많은 것이 요구되며 결코 사라지지 않았습니다.

이러한 관점에서 컴퓨터 비전을 위한 Transformer의 발전은 컨볼루션을 다시 가져오는 것을 목표로 했습니다. 그러나 이러한 시도에는 비용이 따릅니다. 슬라이딩 윈도우 자체 주의를 순진하게 구현하면 비용이 많이 들 수 있습니다. 순환 이동과 같은 고급 접근 방식을 사용하면 속도를 최적화할 수 있지만 시스템 설계가 더욱 정교해집니다. 반면에 ConvNet이 이미 간단하고 꾸밈없는 방식으로 이러한 많은 바람직한 속성을 충족한다는 것은 거의 아이러니합니다. ConvNet이 힘을 잃는 것처럼 보이는 유일한 이유는 (계층적) Transformer가 많은 비전 작업에서 이를 능가하고 성능 차이는 일반적으로 Transformer의 뛰어난 확장 동작으로 인한 것으로, 다중 헤드 자체 주의가 핵심 구성 요소입니다.

지난 10년 동안 점진적으로 개선된 ConvNet과 달리 Vision Transformers의 채택은 단계적인 변화였습니다. 최근 문헌에서 시스템 수준 비교(예: Swin Transformer 대 ResNet)는 일반적으로 둘을 비교할 때 채택됩니다. ConvNet과 계층적 비전 Transformer는 동시에 서로 다르고 유사해집니다. 둘 다 유사한 유도 편향을 갖추고 있지만 훈련 절차 및 매크로/마이크로 수준 아키텍처 설계가 크게 다릅니다. 이 작업에서는 ConvNet과 Transformer 간의 아키텍처 차이점을 조사하고 네트워크 성능을 비교할 때 혼동되는 변수를 식별하려고 합니다. 본 연구는 ConvNet의 ViT 이전 시대와 ViT 이후 시대 간의 격차를 해소하고 순수 ConvNet이 달성할 수 있는 한계를 테스트하기 위한 것입니다.

이를 위해 개선된 절차로 훈련된 표준 ResNet(예: ResNet50)부터 시작합니다. 계층적 비전 Transformer(예: Swin-T) 구성을 위해 아키텍처를 점진적으로 "현대화"합니다. 본 연구는 Transformer의 설계 결정이 ConvNet의 성능에 어떤 영향을 미치는지라는 주요 질문에 의해 진행됩니다. 그 과정에서 성능 차이에 기여하는 몇 가지 주요 구성 요소를 발견합니다. 결과적으로 ConvNeXt라고 불리는 순수 ConvNet 제품군을 제안합니다. ImageNet 분류, COCO의 객체 감지/분할  및 ADE20K의 의미 분할과 같은 다양한 비전 작업에서 ConvNeXt를 평가합니다. 놀랍게도 표준 ConvNet 모듈로 전체 구성된 ConvNeXt는 모든 주요 벤치마크에서 정확도, 확장성 및 견고성 측면에서 Transformer에 필적하는 성능을 보입니다. ConvNeXt는 표준 ConvNet의 효율성을 유지하며 교육 및 테스트 모두에 대한 완전 컨볼루션 특성으로 인해 구현이 매우 간단합니다. 우리는 이러한 새로운 결과와 논의가 몇 가지 일반적인 믿음에 도전하고 컴퓨터 비전에서 컨볼루션의 중요성을 재고하도록 사람들을 격려하기를 바랍니다.


# 2. Modernizing a ConvNet: a Roadmap
이 섹션에서는 ResNet에서 Transformer와 유사한 ConvNet으로 이동하는 궤적을 제공합니다. FLOP 측면에서 두 가지 모델 크기를 고려합니다. 하나는 FLOP가 약 4.5×10^9인 ResNet-50/Swin-T 체제이고 다른 하나는 FLOP가 약 15.0×10^9인 ResNet-200/Swin-B 체제입니다. 간단하게 ResNet-50/Swin-T 복잡도 모델의 결과를 보여드리겠습니다. 더 높은 용량 모델에 대한 결론은 일치하며 결과는 부록 C에서 찾을 수 있습니다.

※ FLOP(FLoating-point OPerations)
:  컴퓨터가 수행하는 부동 소수점 연산 횟수를 의미합니다. 딥러닝 모델의 복잡도를 나타내는 지표로 널리 사용되며, 모델의 학습 및 추론에 필요한 계산량을 추정하는 데 활용됩니다. FLOP이 높을수록 모델이 더 복잡하고 많은 계산이 필요하다는 것을 의미합니다. \
쉽게 말해, FLOP은 모델이 얼마나 많은 계산을 해야 하는지를 나타내는 숫자라고 생각하면 됩니다. 예를 들어, 덧셈, 뺄셈, 곱셈, 나눗셈과 같은 연산을 몇 번 해야 하는지 세는 것이죠. 딥러닝 모델은 수많은 연산을 수행하므로 FLOP은 모델의 크기나 성능을 비교할 때 중요한 기준이 됩니다.

높은 수준에서 우리의 탐색은 표준 ConvNet으로서 네트워크의 단순성을 유지하면서 Swin Transformer의 다양한 수준의 디자인을 조사하고 따르도록 지시됩니다. 탐색 로드맵은 다음과 같습니다. 시작점은 ResNet-50 모델입니다. 먼저 비전 트랜스포머를 교육하는 데 사용되는 유사한 교육 기술로 교육하고 원래 ResNet-50에 비해 훨씬 향상된 결과를 얻습니다. 이것이 우리의 기준선이 될 것입니다. 그런 다음 1) Macro Design, 2) ResNeXt, 3) Inverted Bottleneck, 4) Large Kernel 5) 다양한 레이어별 Micro Design으로 요약한 일련의 디자인 결정을 연구합니다. 그림 2에서는 "네트워크 현대화"의 각 단계를 통해 절차와 결과를 보여줍니다. 네트워크 복잡성은 최종 성능과 밀접하게 관련되어 있으므로 탐색 과정에서 FLOP는 대략적으로 제어되지만 중간 단계에서는 FLOP가 참조 모델보다 높거나 낮을 수 있습니다. 모든 모델은 ImageNet-1K에서 훈련 및 평가됩니다.

![figure2]()
어텐션 기반 모듈을 도입하지 않고 표준 ConvNet(ResNet)을 계층적 비전 Transformer(Swin) 설계 방향으로 현대화합니다. 전경 막대는 ResNet-50/Swin-T FLOP 체제의 모델 정확도입니다. ResNet-200/Swin-B 체제의 결과는 회색 막대로 표시됩니다. 빗금 막대는 수정이 채택되지 않았음을 의미합니다. 두 체제에 대한 자세한 결과는 부록에 있습니다. 많은 Transformer 아키텍처 선택이 ConvNet에 통합될 수 있으며 성능이 점점 더 향상됩니다. 결국 ConvNeXt라는 순수 ConvNet 모델은 Swin Transformer보다 성능이 뛰어날 수 있습니다.

### 2.1. Training Techniques
네트워크 아키텍처의 설계 외에도 훈련 절차는 궁극적인 성능에도 영향을 미칩니다. 비전 트랜스포머는 새로운 모듈 세트와 아키텍처 설계 결정을 가져왔을 뿐만 아니라 비전에 서로 다른 교육 기술(예: AdamW 옵티마이저)을 도입했습니다. 이것은 주로 최적화 전략 및 관련 하이퍼 매개변수 설정과 관련이 있습니다. 따라서 탐색의 첫 번째 단계는 비전 트랜스포머 교육 절차, 즉 ResNet50/200을 사용하여 기준선 모델을 교육하는 것입니다. 최근 연구에서는 현대적인 교육 기술 세트가 간단한 ResNet-50 모델의 성능을 크게 향상시킬 수 있음을 보여줍니다. 본 연구에서는 DeiT  및 Swin Transformer에 가까운 교육 레시피를 사용합니다. ResNet의 경우 교육이 원래 90 에포크에서 300 에포크로 확장됩니다. AdamW 옵티마이저, Mixup, Cutmix, RandAugment, Random Erasing과 같은 데이터 증강 기술 및 Stochastic Depth 및 Label Smoothing를 포함한 정규화 체계를 사용합니다. 우리가 사용하는 전체 하이퍼 매개변수 세트는 부록 A.1에서 찾을 수 있습니다.

이 향상된 교육 레시피 자체만으로도 ResNet-50 모델의 성능이 76.1%에서 78.8%(+2.7%)로 증가하여 기존 ConvNet과 비전 트랜스포머 간의 성능 차이의 상당 부분이 교육 기술 때문일 수 있음을 의미합니다. "현대화" 프로세스 전체에서 동일한 하이퍼 매개변수와 함께 이 고정 교육 레시피를 사용합니다. ResNet-50 체제에 대해 보고된 각 정확도는 세 가지 서로 다른 무작위 시드로 훈련하여 얻은 평균입니다.

### 2.2. Macro Design
이제 Swin Transformers의 매크로 네트워크 설계를 분석합니다. Swin Transformers는 ConvNets에 따라 각 단계마다 다른 기능 맵 해상도를 갖는 다단계 설계를 사용합니다. 스테이지 컴퓨팅 비율과 "줄기 세포" 구조라는 두 가지 흥미로운 디자인 고려 사항이 있습니다.

#### 단계별 계산 비율 변경. 
ResNet에서 단계 간 계산 분포의 원래 설계는 대체로 경험적이었습니다. 무거운 "res4" 단계는 감지기 헤드가 14×14 피쳐 평면에서 작동하는 객체 감지와 같은 다운스트림 작업과 호환되도록 의도되었습니다. 반면 Swin-T는 동일한 원칙을 따랐지만 약간 다른 1:1:3:1의 단계 계산 비율을 사용했습니다. 더 큰 Swin Transformers의 경우 비율은 1:1:9:1입니다. 설계에 따라 각 단계의 블록 수를 ResNet-50의 (3, 4, 6, 3)에서 (3, 3, 9, 3)으로 조정하여 FLOP를 Swin-T와 정렬합니다. 이렇게 하면 모델 정확도가 78.8%에서 79.4%로 향상됩니다. 특히 연구원들은 계산 분포 [53, 54]를 철저히 조사했으며 더 최적화된 설계가 존재할 가능성이 높습니다. 지금부터 이 단계 계산 비율을 사용하겠습니다.

#### 줄기를 "Patchify"로 변경. 
일반적으로 줄기 세포 설계는 입력 이미지가 네트워크 시작 부분에서 어떻게 처리될지에 대한 것입니다. 자연 이미지에 내재된 중복성으로 인해 일반적인 줄기 세포는 표준 ConvNet 및 비전 트랜스포머 모두에서 입력 이미지를 적절한 피처 맵 크기로 적극적으로 다운샘플링합니다. 표준 ResNet의 줄기 세포에는 보폭 2의 7×7 컨볼루션 계층과 그 뒤에 최대 풀이 포함되어 있어 입력 이미지가 4× 다운샘플링됩니다. 비전 트랜스포머에서는 더 공격적인 "패치화" 전략이 줄기 세포로 사용되는데, 이는 큰 커널 크기(예: 커널 크기 = 14 또는 16) 및 겹치지 않는 컨볼루션에 해당합니다. Swin Transformer는 유사한 "패치화" 레이어를 사용하지만 아키텍처의 다단계 설계를 수용하기 위해 더 작은 패치 크기 4를 사용합니다. ResNet 스타일 줄기 세포를 4×4, 보폭 4 컨볼루션 레이어를 사용하여 구현된 패치 레이어로 교체합니다. 정확도는 79.4%에서 79.5%로 변경되었습니다. 이는 ResNet의 줄기 세포를 ViT와 유사한 더 간단한 "패치화" 레이어로 대체하면 유사한 성능을 얻을 수 있음을 시사합니다. 이제 네트워크에서 "패치 줄기"(4×4 비 중첩 컨볼루션)를 사용합니다.


## 2.3. ResNeXt-ify
이 부분에서는 ResNeXt라는 모델의 아이디어를 ResNet에 적용하는 과정을 설명합니다. ResNeXt는 ResNet보다 연산량 대비 정확도가 더 좋은 모델입니다. ResNeXt의 핵심은 그룹 컨볼루션(grouped convolution)을 사용하는 것인데, 컨볼루션 필터를 여러 그룹으로 나누어 연산하는 방식입니다. ResNeXt의 기본 원리는 "그룹을 더 많이 사용하고, 너비(채널 수)를 확장한다"는 것입니다. 그룹 컨볼루션을 사용하면 연산량이 줄어들기 때문에, 줄어든 정보량을 보상하기 위해 네트워크의 너비를 늘립니다. 본 논문에서는 그룹 컨볼루션의 특별한 형태인 깊이별 컨볼루션(depthwise convolution)을 사용합니다. 깊이별 컨볼루션은 그룹 수가 채널 수와 같은 경우이며, MobileNet과 Xception에서 널리 사용되었습니다. 깊이별 컨볼루션은 각 채널별로 독립적인 연산을 수행하므로 공간 정보만 혼합하고 채널 정보는 혼합하지 않습니다. 이는 Vision Transformer의 self-attention과 유사한 특징입니다. ResNet-50 모델에 깊이별 컨볼루션을 적용하면 네트워크의 연산량은 줄어들지만 정확도도 감소합니다. 따라서 ResNeXt 전략에 따라 네트워크의 너비를 Swin-T 모델과 동일한 96개 채널로 늘려줍니다. 이렇게 하면 FLOPs(연산량)는 5.3G로 증가하지만 정확도는 80.5%로 향상됩니다.

※ 그룹 컨볼루션(Grouped Convolution) \
: 컨볼루션 신경망(CNN)에서 사용되는 합성곱 연산의 한 종류입니다. 일반적인 합성곱 연산은 입력 채널 전체에 대해 하나의 필터를 적용하는 반면, 그룹 컨볼루션은 입력 채널을 여러 그룹으로 나누고 각 그룹에 대해 별도의 필터를 적용

※ 깊이별 컨볼루션(depthwise convolution) \
: 그룹 컨볼루션(grouped convolution)의 특별한 경우로, 각 그룹이 하나의 입력 채널만을 담당하는 합성곱 연산입니다. 다시 말해, 깊이별 컨볼루션은 각 채널에 대해 독립적인 필터를 적용하여 특징 맵을 생성하는 방식입니다.

※ Vision Transformer(ViT) \
: 자연어 처리 분야에서 널리 사용되는 Transformer 모델을 이미지 인식 작업에 적용한 모델입니다. 기존의 컨볼루션 신경망(CNN)과는 달리, ViT는 이미지를 작은 패치(patch)로 나누고 각 패치를 자연어 처리에서 단어처럼 취급하여 패치 간의 관계를 분석하고 이미지 전체를 이해합니다.

※ Self-attention
: 트랜스포머 모델의 핵심 구성 요소로, 입력 데이터의 각 요소가 다른 모든 요소와의 관계를 계산하여 중요도를 파악하는 메커니즘 \
쉽게 설명하면, self-attention은 문장 속의 각 단어가 다른 단어들과 얼마나 관련이 있는지를 파악하는 것과 비슷합니다. 예를 들어 "나는 오늘 맛있는 사과를 먹었다"라는 문장에서 "사과"라는 단어는 "먹었다"라는 단어와 높은 관련성을 가지지만, "나는"이나 "오늘"과는 관련성이 낮습니다. Self-attention은 이러한 관련성을 수치화하여 각 단어의 중요도를 나타내는 가중치를 부여합니다.


## 2.4. Inverted Bottleneck
모든 Transformer 블록의 중요한 설계 중 하나는 inverted bottleneck을 생성한다는 것입니다. 즉, MLP 블록의 hidden dimension이 입력 dimension보다 4배 더 넓습니다(그림 4 참조). 흥미롭게도 이 Transformer 디자인은 ConvNet에서 확장 비율이 4인 inverted bottleneck 디자인과 연결됩니다. 이 아이디어는 MobileNetV2 [61]에 의해 대중화되었으며 이후 여러 고급 ConvNet 아키텍처 [70, 71]에서 인기를 얻었습니다.
![figure4]() 


여기에서 inverted bottleneck 디자인을 살펴봅니다. 그림 3 (a)에서 (b)는 구성을 보여줍니다. 깊이별 컨볼루션 레이어의 FLOP가 증가했음에도 불구하고 이 변경으로 인해 다운샘플링 residual 블록의 shortcut 1x1 conv 레이어에서 FLOP가 크게 감소하여 전체 네트워크 FLOP가 4.6G로 감소합니다. 흥미롭게도 이는 성능이 약간 향상됩니다(80.5%에서 80.6%). ResNet-200/Swin-B 체제에서 이 단계는 FLOP 감소와 함께 더 많은 이득(81.9%에서 82.6%)을 가져옵니다.

이제 inverted bottleneck을 사용합니다.

※ MLP(Multi-Layer Perceptron) \
: 다층 퍼셉트론이라고도 불리며, 가장 기본적인 형태의 인공 신경망입니다. 입력층, 은닉층(hidden layer), 출력층으로 구성되어 있으며, 각 층은 여러 개의 뉴런(노드)으로 이루어져 있습니다. 각 뉴런은 입력 값을 받아 가중치를 곱하고 활성화 함수를 거쳐 출력 값을 생성합니다. 이러한 과정을 통해 MLP는 복잡한 패턴을 학습하고 예측할 수 있습니다

























---