CNN이 transformer가 일반적으로 활용하는 최신 training 트릭을 훔쳐 궁극적인 CNN 아키텍처를 구축한다.

ConvNext은 매우 흥미롭다. 왜냐하면 CNN을 단계별로 현대화하면 어디에서 성능을 얻을 수 있는지 더 잘 알 수 있기 때문이다. 
ConvNext은는 이미지 분류뿐만 아니라 지금까지 Swin transformer 가 지배했던 객체 감지 및 이미지 분할에도 transformer와 경쟁한다.

CNN vs transformer
저자는 CNN을 칭찮며 논문을 소개한다. 그들의 의제는 CNN을 부활시키는 것이다.

2017년에 텍스트 처리용 transformer가 도입된 후 transformer는 실제로 이미지 생성 또는 이미지 - 텍스트 이해에 일부 응용프로그램을 가졌다. transformer 아키텍처는 imagenet에서 최첨단 기술을 발전시키는 것으로 입증되었을때 컴퓨터 비전 커뮤니티에서 제대로 주목받았다.  
그래서 transformer의 어떤 점이 멋있을까?
1. 자연어처리에서 알려진 transformer는 이미지에 대해 기본적으로 어느 정도 사용할 수 있다. 
예외는 다음과 같다 : patchify. 예를들어 16 * 16 픽셀의 이미지를 일련의 패치로 분할하는 초기 패치화 레이어에는 ViT가 있다. ViT의 확장 법칙을 사용하면 모델 크기와 훈련 데이터의 크기를 늘릴 수 있으며, resnet을 극복한다. 하지만 vit의 문제는 바로 슬라이딩 윈도우로 인한 유도 바이어스가 없으면 변환기의 솔루션 공간이 CNN보다 크다. CNN은 구조상 번역 등변성(?)이 아닌 어떤 것으로도 수렴할 수 없다. 하지만 transformer는 이러한 안내 편향ㅇ르 놓치기 때문에 매우 잘할 수 있다. 이는 transformer의 솔류션 공간이 더 크다는 의미이다. 솔루션 공간이 더 크기 때문에 아키텍처가 더 유연하다. 따라서 더 큰 공간에서 올바른 솔루션을 찾기 위한 훈련 데이터가 거의 없는 경우 transformer는 deit에서 본것처럼 과도한 데이터 증대와 같은 많은 훈련 트릭에 의존한다. 하지만 transformer의 가장 큰 문제는 imagenet 시나리오를 제외한 모든 것이다. 따라서 이미지가 고해상도이고 예측이 조밀해야하는 경우, 16*16 픽셀로 패치하는 것은 올바른 픽셀수준 예측을 하기에는 너무 거칠 수 있다. 하지만 패치를 더 작게 만들면 동일한 표면을 덮기 위해 더 많은 패치가 필요하기 때문에 시퀀스 길이가 2차적으로 증가한다. 그리고 transformer의 시퀀스 길이를 늘리면 컴퓨팅 및 메모리 공간이 다시 2차적으로 증가한다. 이를 극복하기 위해 swin transformer와 같은 hierarchical transformer는 슬라이딩 윈도우를 다시 도입하여 이러한 측면에서 CNN과 매우 유사하다. 
이점에 주목하여 저자는 CNN을 swintransformer로 변형한다면 어떻게 될지에 대한 질문에 대답하기 위해 

resnet50을 사용한다. 저자는 또한 더 큰 resnet200으로 실험을 했지만 이에 대해 더 알고 싶다면 부록 C를 읽으면 된다. 
우선 무엇보다도 저자는 비전 transformer가 훈련받은 것과 유사한 기술로 이를 훈련한다. 
Adamw 최적화 프로그램을 사용하고 더 많은 에폭을 사용하며 데이터 증대, 정규화를 사용한다. 이 모든 것이 imagenet top1 정확도에서 resnet-50의 성능을 76.1% -> 78.8%로 향상시킨다. 

두번째로 현대화하는 것은 macro design이다. 단계 비율의 경우 각 단계의 블록 수를 조정하고 모델 정확도를 향상시킨다. 그런 다움 resnet의 슬랑이딩 창이 비전 transformer의 패치처럼 작동하도록 만든다. 따라서 더 큰 커널 크기와 슬라이딩 창이 겹치지 않는 보폭을 사용하면 이는 이미 다음의 비중첩 패치와 훨씬 비슷해보인다. 이렇게 하면 약간이라도 성능이 향상된다. 

세번째 단계에서는 Resnext가 이전에 소개한 아이디어, 즉 정보분할, 변환 및 병합에 대한 inception 아이디어를 채택한다. 여기서 키워드는 깊이별 컨볼루션 수(그룹는 채널수와 동일한 그룹화된 컨볼루션의 특별한 경우) 이다. 
중요한 점은 다음과 같다. 깊이별 컨볼루션은 self-attention의 가중 합 연산과 유사하다. 이는 채널별로 작동한다. 즉 정보만 혼합하는 것이다. 공간적 차원 견적을 종료한다. 
그리고 depth conv으로 flop 수를 줄이면 정확도도 떨어지지만 동시에 네트워크를 확장하면 성능이 크게 향상된다. 

이제 전체 개선 프로세스의 네번째 단계인 inverted bottleneck이 필요한 시점이다. 
모든 transformer 블록의 중요한 설계 중 하나는 inverted bottleneck 현상을 생성한다. 즉, MLP 블록의 숨겨진 차원은 입력의 4배 더 넓습니다. 
-> 이 부분에서 일반적으로 모든 transformer가 아니라 swin transformer가 그렇다는 것이다. 이 말은 오해의 소지가 있다.

다섯번째 단계에서는 더 큰 커널 크기를 도입한다. 이는 전역수용 필드를 갖고 전체 이미지에 걸쳐 있는 self-attention을 통해 이미지를 한번에 볼 수 있는 비전 변환기의 힘과 동일하려고 한다. 
그러나 swin transformer는 self-attention창을 제한하므로 작성자가 resnets 창 크기를 늘리면 동일한 절충안을 도달해야한다. 하지만 이로 인해 성능이 향상되지는 않았다. 하지만 커널 크기가 작으면 성능이 저하되는 것은 분명하다. 

마지막으로 여섯번째단계에는 다음과 같은 마이크로 디자인이 제공된다. relu활성화 기능을 gelu로 교체한다. transformer도 마찬가지로 활성화기능을 덜 자주 사용하고 있다. 그리고 동일한 동기로 더 많은 transformer 스타일을 수행하기 위해 저자는 또한 transformer가 resnet보다 정규화 레이어를 덜 자주 사용하기 때문에 더 적은 수의 정규화 레이어를 사용한다. 
일괄 정규화를 레이어 졍규화로 대체하고 있다. 
여러개의 예와 기능이 연결된 미니 데이터 배치인 batchnorm에서 정규화는 배치/샘플 차원 전체에 걸쳐 바랭한다. 
일괄 정규화 효과는 특성의 크기가 일괄 처리의 데이터 샘플 전체에서 유사하다는 것이다. layernorm은 데이터 샘플별로 특성의 크기가 거의 동일하도록 특성 차원 전체에 걸쳐 정규화한다. 역사적으로 layernorm은 순환 신경망에 더 잘 작동하는 반면 batchnorm은 주로 CNN에 사용되었다. 
놀랍게도 micro design의 미세한 증가는 성능에 엄청난 영향을 미치며 별도의 다운 샘플링 레이어를 사용하여 이 향상된 resnet은 swin transformer를 능가하는 82.0% imagenet top1 정확도를 달성한다. 
transformer는 계산 및 크기 측면에서 동일한 리그에 속하기 때문에 이러한 결과는 비교할 수 있다. 

CNN vs transformer 에서 얻을 수 있는 교훈은 
1. transformer뿐만 아니라 CNN도 크기와 데이터 측면에서 확장된다.
2. convnext는 vit의 계층적 버전이었던 swin transformer와 객체 감지 및 의미론적 분할에서 경쟁할 수 있다.

지금까지 우리는 self attention과 transformer가 병렬 고속도로에서 정보를 처리하는 방식이 성공의 비결이라고 생각했다. 하지만 이 논문에서는 최첨단 방식으로 전환할 수 있는 것은 아키텍처 자체가 아니라 겉으로 보기에 아주 작은 아키텍처 하이퍼파라미터가 많다는 것을 시사한다.  
비록 새로운 디자인 옵션이 제시되지 않았지만 모든 것을 하나로 모으는 기술, 또는 오히려 사용가능한 모든 옵션을 무차별 대입하는 힘이 이 논문을 견딜 수 있게 만드는 것이다. 